# Chunk 3
sample_text <- paste(blogs, news, twitter)
# Chunk 4
corpus <- VCorpus(VectorSource(sample_text))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
# Chunk 5
df <- data.frame(text=unlist(sapply(corpus, '[',"content")),stringsAsFactors=F)
# Chunk 6
token_delim <- " \\t\\r\\n.!?,;\"()"
onetoken <- NGramTokenizer(df, Weka_control(min=1,max=1))
bitoken <- NGramTokenizer(df, Weka_control(min=2,max=2, delimiters = token_delim))
tritoken <- NGramTokenizer(df, Weka_control(min=3, max=3, delimiters = token_delim))
quatrtoken <- NGramTokenizer(df, Weka_control(min=4, max=4, delimiters = token_delim))
# Chunk 7
one_word <- data.frame(table(onetoken))
two_word <- data.frame(table(bitoken))
three_word <- data.frame(table(tritoken))
four_word <- data.frame(table(quatrtoken))
sort_one <- one_word[order(one_word$Freq,decreasing=TRUE),]
colnames(sort_one) <- c("Word", "Freq")
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
colnames(sort_two) <- c("Word", "Freq")
sort_three <- three_word[order(three_word$Freq,decreasing=TRUE),]
colnames(sort_three) <- c("Word", "Freq")
sort_four <- four_word[order(four_word$Freq,decreasing=TRUE),]
colnames(sort_four) <- c("Word", "Freq")
# Chunk 8
wordcloud(words = sort_two[1:10,1], freq = sort_two[1:10,2], scale=c(5,1), colors = brewer.pal(10,"BrBG"),ordered.colors=TRUE)
# Chunk 9
wordcloud(words = sort_three[1:10,1], freq = sort_two[1:10,2], scale=c(4,1), colors = brewer.pal(10,"PiYG"),ordered.colors=TRUE)
# Chunk 10
wordcloud(words = sort_four[1:10,1], freq = sort_two[1:10,2], scale=c(3,1), colors = brewer.pal(10,"PRGn"),ordered.colors=TRUE)
# Chunk 11
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.50){
running_freq <- running_freq + sort_one_freq[words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 12
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.90){
running_freq <- running_freq + sort_one_freq[(words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 1
library(knitr)
library(scales)
library(RGraphics)
library(tm)
library(qdap)
library(ggplot2)
library(openNLP)
library(ngram)
library(sqldf)
library(RColorBrewer)
library(RSQLite)
require(RWeka)
require(SnowballC)
library(wordcloud)
# Chunk 2
blogs <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
news <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.news.txt", 10000)
twitter <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
# Chunk 3
sample_text <- paste(blogs, news, twitter)
# Chunk 4
corpus <- VCorpus(VectorSource(sample_text))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
# Chunk 5
df <- data.frame(text=unlist(sapply(corpus, '[',"content")),stringsAsFactors=F)
# Chunk 6
token_delim <- " \\t\\r\\n.!?,;\"()"
onetoken <- NGramTokenizer(df, Weka_control(min=1,max=1))
bitoken <- NGramTokenizer(df, Weka_control(min=2,max=2, delimiters = token_delim))
tritoken <- NGramTokenizer(df, Weka_control(min=3, max=3, delimiters = token_delim))
quatrtoken <- NGramTokenizer(df, Weka_control(min=4, max=4, delimiters = token_delim))
# Chunk 7
one_word <- data.frame(table(onetoken))
two_word <- data.frame(table(bitoken))
three_word <- data.frame(table(tritoken))
four_word <- data.frame(table(quatrtoken))
sort_one <- one_word[order(one_word$Freq,decreasing=TRUE),]
colnames(sort_one) <- c("Word", "Freq")
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
colnames(sort_two) <- c("Word", "Freq")
sort_three <- three_word[order(three_word$Freq,decreasing=TRUE),]
colnames(sort_three) <- c("Word", "Freq")
sort_four <- four_word[order(four_word$Freq,decreasing=TRUE),]
colnames(sort_four) <- c("Word", "Freq")
# Chunk 8
wordcloud(words = sort_two[1:10,1], freq = sort_two[1:10,2], scale=c(5,1), colors = brewer.pal(10,"BrBG"),ordered.colors=TRUE)
# Chunk 9
wordcloud(words = sort_three[1:10,1], freq = sort_two[1:10,2], scale=c(4,1), colors = brewer.pal(10,"PiYG"),ordered.colors=TRUE)
# Chunk 10
wordcloud(words = sort_four[1:10,1], freq = sort_two[1:10,2], scale=c(3,1), colors = brewer.pal(10,"PRGn"),ordered.colors=TRUE)
# Chunk 11
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.50){
running_freq <- running_freq + sort_one_freq[words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 12
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.90){
running_freq <- running_freq + sort_one_freq[(words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 1
library(knitr)
library(scales)
library(RGraphics)
library(tm)
library(qdap)
library(ggplot2)
library(openNLP)
library(ngram)
library(sqldf)
library(RColorBrewer)
library(RSQLite)
require(RWeka)
require(SnowballC)
library(wordcloud)
# Chunk 2
blogs <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
news <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.news.txt", 10000)
twitter <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
# Chunk 3
sample_text <- paste(blogs, news, twitter)
# Chunk 4
corpus <- VCorpus(VectorSource(sample_text))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
# Chunk 5
df <- data.frame(text=unlist(sapply(corpus, '[',"content")),stringsAsFactors=F)
# Chunk 6
token_delim <- " \\t\\r\\n.!?,;\"()"
onetoken <- NGramTokenizer(df, Weka_control(min=1,max=1))
bitoken <- NGramTokenizer(df, Weka_control(min=2,max=2, delimiters = token_delim))
tritoken <- NGramTokenizer(df, Weka_control(min=3, max=3, delimiters = token_delim))
quatrtoken <- NGramTokenizer(df, Weka_control(min=4, max=4, delimiters = token_delim))
# Chunk 7
one_word <- data.frame(table(onetoken))
two_word <- data.frame(table(bitoken))
three_word <- data.frame(table(tritoken))
four_word <- data.frame(table(quatrtoken))
sort_one <- one_word[order(one_word$Freq,decreasing=TRUE),]
colnames(sort_one) <- c("Word", "Freq")
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
colnames(sort_two) <- c("Word", "Freq")
sort_three <- three_word[order(three_word$Freq,decreasing=TRUE),]
colnames(sort_three) <- c("Word", "Freq")
sort_four <- four_word[order(four_word$Freq,decreasing=TRUE),]
colnames(sort_four) <- c("Word", "Freq")
# Chunk 8
wordcloud(words = sort_two[1:10,1], freq = sort_two[1:10,2], scale=c(5,1), colors = brewer.pal(10,"BrBG"),ordered.colors=TRUE)
# Chunk 9
wordcloud(words = sort_three[1:10,1], freq = sort_two[1:10,2], scale=c(4,1), colors = brewer.pal(10,"PiYG"),ordered.colors=TRUE)
# Chunk 10
wordcloud(words = sort_four[1:10,1], freq = sort_two[1:10,2], scale=c(3,1), colors = brewer.pal(10,"PRGn"),ordered.colors=TRUE)
# Chunk 11
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.50){
running_freq <- running_freq + sort_one_freq[words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 12
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.90){
running_freq <- running_freq + sort_one_freq[(words_counted+1),3]
words_counted <- words_counted + 1}
install.packages("rJava")
# Chunk 1
library(knitr)
library(scales)
library(RGraphics)
library(tm)
library(qdap)
library(ggplot2)
library(openNLP)
library(ngram)
library(sqldf)
library(RColorBrewer)
library(RSQLite)
require(Rjava)
require(RWeka)
require(SnowballC)
library(wordcloud)
# Chunk 2
blogs <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
news <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.news.txt", 10000)
twitter <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
# Chunk 3
sample_text <- paste(blogs, news, twitter)
# Chunk 4
corpus <- VCorpus(VectorSource(sample_text))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
# Chunk 5
df <- data.frame(text=unlist(sapply(corpus, '[',"content")),stringsAsFactors=F)
# Chunk 6
token_delim <- " \\t\\r\\n.!?,;\"()"
onetoken <- NGramTokenizer(df, Weka_control(min=1,max=1))
bitoken <- NGramTokenizer(df, Weka_control(min=2,max=2, delimiters = token_delim))
tritoken <- NGramTokenizer(df, Weka_control(min=3, max=3, delimiters = token_delim))
quatrtoken <- NGramTokenizer(df, Weka_control(min=4, max=4, delimiters = token_delim))
# Chunk 7
one_word <- data.frame(table(onetoken))
two_word <- data.frame(table(bitoken))
three_word <- data.frame(table(tritoken))
four_word <- data.frame(table(quatrtoken))
sort_one <- one_word[order(one_word$Freq,decreasing=TRUE),]
colnames(sort_one) <- c("Word", "Freq")
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
colnames(sort_two) <- c("Word", "Freq")
sort_three <- three_word[order(three_word$Freq,decreasing=TRUE),]
colnames(sort_three) <- c("Word", "Freq")
sort_four <- four_word[order(four_word$Freq,decreasing=TRUE),]
colnames(sort_four) <- c("Word", "Freq")
# Chunk 8
wordcloud(words = sort_two[1:10,1], freq = sort_two[1:10,2], scale=c(5,1), colors = brewer.pal(10,"BrBG"),ordered.colors=TRUE)
# Chunk 9
wordcloud(words = sort_three[1:10,1], freq = sort_two[1:10,2], scale=c(4,1), colors = brewer.pal(10,"PiYG"),ordered.colors=TRUE)
# Chunk 10
wordcloud(words = sort_four[1:10,1], freq = sort_two[1:10,2], scale=c(3,1), colors = brewer.pal(10,"PRGn"),ordered.colors=TRUE)
# Chunk 11
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.50){
running_freq <- running_freq + sort_one_freq[words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 12
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.90){
running_freq <- running_freq + sort_one_freq[(words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 1
library(knitr)
library(scales)
library(RGraphics)
library(tm)
library(qdap)
library(ggplot2)
library(openNLP)
library(ngram)
library(sqldf)
library(RColorBrewer)
library(RSQLite)
require(Rjava)
require(RWeka)
require(SnowballC)
library(wordcloud)
registerDoMC(cores = 8)
# Chunk 2
blogs <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
news <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.news.txt", 10000)
twitter <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
# Chunk 3
sample_text <- paste(blogs, news, twitter)
# Chunk 4
corpus <- VCorpus(VectorSource(sample_text))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
# Chunk 5
df <- data.frame(text=unlist(sapply(corpus, '[',"content")),stringsAsFactors=F)
# Chunk 6
token_delim <- " \\t\\r\\n.!?,;\"()"
onetoken <- NGramTokenizer(df, Weka_control(min=1,max=1))
bitoken <- NGramTokenizer(df, Weka_control(min=2,max=2, delimiters = token_delim))
tritoken <- NGramTokenizer(df, Weka_control(min=3, max=3, delimiters = token_delim))
quatrtoken <- NGramTokenizer(df, Weka_control(min=4, max=4, delimiters = token_delim))
# Chunk 7
one_word <- data.frame(table(onetoken))
two_word <- data.frame(table(bitoken))
three_word <- data.frame(table(tritoken))
four_word <- data.frame(table(quatrtoken))
sort_one <- one_word[order(one_word$Freq,decreasing=TRUE),]
colnames(sort_one) <- c("Word", "Freq")
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
colnames(sort_two) <- c("Word", "Freq")
sort_three <- three_word[order(three_word$Freq,decreasing=TRUE),]
colnames(sort_three) <- c("Word", "Freq")
sort_four <- four_word[order(four_word$Freq,decreasing=TRUE),]
colnames(sort_four) <- c("Word", "Freq")
# Chunk 8
wordcloud(words = sort_two[1:10,1], freq = sort_two[1:10,2], scale=c(5,1), colors = brewer.pal(10,"BrBG"),ordered.colors=TRUE)
# Chunk 9
wordcloud(words = sort_three[1:10,1], freq = sort_two[1:10,2], scale=c(4,1), colors = brewer.pal(10,"PiYG"),ordered.colors=TRUE)
# Chunk 10
wordcloud(words = sort_four[1:10,1], freq = sort_two[1:10,2], scale=c(3,1), colors = brewer.pal(10,"PRGn"),ordered.colors=TRUE)
# Chunk 11
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.50){
running_freq <- running_freq + sort_one_freq[words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 12
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.90){
running_freq <- running_freq + sort_one_freq[(words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 1
library(knitr)
library(scales)
library(RGraphics)
library(tm)
library(qdap)
library(ggplot2)
library(openNLP)
library(ngram)
library(sqldf)
library(RColorBrewer)
library(RSQLite)
require(Rjava)
require(RWeka)
require(SnowballC)
library(wordcloud)
registerDoMC(cores = 8)
# Chunk 2
blogs <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
news <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.news.txt", 10000)
twitter <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
# Chunk 3
sample_text <- paste(blogs, news, twitter)
# Chunk 4
corpus <- VCorpus(VectorSource(sample_text))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
# Chunk 5
df <- data.frame(text=unlist(sapply(corpus, '[',"content")),stringsAsFactors=F)
# Chunk 6
token_delim <- " \\t\\r\\n.!?,;\"()"
onetoken <- NGramTokenizer(df, Weka_control(min=1,max=1))
bitoken <- NGramTokenizer(df, Weka_control(min=2,max=2, delimiters = token_delim))
tritoken <- NGramTokenizer(df, Weka_control(min=3, max=3, delimiters = token_delim))
quatrtoken <- NGramTokenizer(df, Weka_control(min=4, max=4, delimiters = token_delim))
# Chunk 7
one_word <- data.frame(table(onetoken))
two_word <- data.frame(table(bitoken))
three_word <- data.frame(table(tritoken))
four_word <- data.frame(table(quatrtoken))
sort_one <- one_word[order(one_word$Freq,decreasing=TRUE),]
colnames(sort_one) <- c("Word", "Freq")
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
colnames(sort_two) <- c("Word", "Freq")
sort_three <- three_word[order(three_word$Freq,decreasing=TRUE),]
colnames(sort_three) <- c("Word", "Freq")
sort_four <- four_word[order(four_word$Freq,decreasing=TRUE),]
colnames(sort_four) <- c("Word", "Freq")
# Chunk 8
wordcloud(words = sort_two[1:10,1], freq = sort_two[1:10,2], scale=c(5,1), colors = brewer.pal(10,"BrBG"),ordered.colors=TRUE)
# Chunk 9
wordcloud(words = sort_three[1:10,1], freq = sort_two[1:10,2], scale=c(4,1), colors = brewer.pal(10,"PiYG"),ordered.colors=TRUE)
# Chunk 10
wordcloud(words = sort_four[1:10,1], freq = sort_two[1:10,2], scale=c(3,1), colors = brewer.pal(10,"PRGn"),ordered.colors=TRUE)
# Chunk 11
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.50){
running_freq <- running_freq + sort_one_freq[words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 12
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.90){
running_freq <- running_freq + sort_one_freq[(words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 1
library(knitr)
library(scales)
library(RGraphics)
library(tm)
library(qdap)
library(ggplot2)
library(openNLP)
library(ngram)
library(sqldf)
library(RColorBrewer)
library(RSQLite)
require(Rjava)
require(RWeka)
require(SnowballC)
library(wordcloud)
registerDoMC(cores = 8)
# Chunk 2
blogs <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
news <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.news.txt", 10000)
twitter <- readLines("C:/Users/Dumbo Yeti/Desktop/CAPSTONE PROJECT SWIFTKEY 2016/final/en_US/en_US.blogs.txt", 10000)
# Chunk 3
sample_text <- paste(blogs, news, twitter)
# Chunk 4
corpus <- VCorpus(VectorSource(sample_text))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
# Chunk 5
df <- data.frame(text=unlist(sapply(corpus, '[',"content")),stringsAsFactors=F)
# Chunk 6
token_delim <- " \\t\\r\\n.!?,;\"()"
# Chunk 7
onetoken <- NGramTokenizer(df, Weka_control(min=1,max=1))
bitoken <- NGramTokenizer(df, Weka_control(min=2,max=2, delimiters = token_delim))
tritoken <- NGramTokenizer(df, Weka_control(min=3, max=3, delimiters = token_delim))
quatrtoken <- NGramTokenizer(df, Weka_control(min=4, max=4, delimiters = token_delim))
# Chunk 8
one_word <- data.frame(table(onetoken))
two_word <- data.frame(table(bitoken))
three_word <- data.frame(table(tritoken))
four_word <- data.frame(table(quatrtoken))
sort_one <- one_word[order(one_word$Freq,decreasing=TRUE),]
colnames(sort_one) <- c("Word", "Freq")
sort_two <- two_word[order(two_word$Freq,decreasing=TRUE),]
colnames(sort_two) <- c("Word", "Freq")
sort_three <- three_word[order(three_word$Freq,decreasing=TRUE),]
colnames(sort_three) <- c("Word", "Freq")
sort_four <- four_word[order(four_word$Freq,decreasing=TRUE),]
colnames(sort_four) <- c("Word", "Freq")
# Chunk 9
wordcloud(words = sort_two[1:10,1], freq = sort_two[1:10,2], scale=c(5,1), colors = brewer.pal(10,"BrBG"),ordered.colors=TRUE)
# Chunk 10
wordcloud(words = sort_three[1:10,1], freq = sort_two[1:10,2], scale=c(4,1), colors = brewer.pal(10,"PiYG"),ordered.colors=TRUE)
# Chunk 11
wordcloud(words = sort_four[1:10,1], freq = sort_two[1:10,2], scale=c(3,1), colors = brewer.pal(10,"PRGn"),ordered.colors=TRUE)
# Chunk 12
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.50){
running_freq <- running_freq + sort_one_freq[words_counted+1),3]
words_counted <- words_counted + 1}
# Chunk 13
sort_one_freq <- cbind(sort_one,sort_one$Freq/sum(sort_one$Freq))
colnames(sort_one_freq) <- c("Word", "Freq", "Pct_Freq")
running_freq = 0
words_counted = 0
while(running_freq<0.90){
running_freq <- running_freq + sort_one_freq[(words_counted+1),3]
words_counted <- words_counted + 1}
Sys.getenv(JAVA_HOME)
Sys.getenv(JAVA_HOME)
Sys.getenv("C:/Program Files(x86)/Java/jre1.8.0.91")
install.packages(c("GGally", "imputeTS", "jsonlite", "plyr", "quantreg", "raster", "RcppArmadillo", "RWeka", "stringi"))
rstudio-server verify-installation
R CMD javareconf
rstudio-server verify-installation
install.packages("rJava")
install.packages("RWeka")
javareconf()
javareconf
java.options()
java.options
R CMD javareconf
CMD javareconf
java.options()
R CMD javareconf
install.packages("rJava", type = "source")
library(rJava)
R CMD INSTALL rJava_0.9-7.tar.gz
wget http://www.rforge.net/&rJava/snapshot/RJava_0.9-7.tar.gz
install.packages("XLConnect")
Sys.setenv(DYLD_FALLBACK_LIBRARY_PATH:"C:/Program Files/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre/lib/server/")
Sys.setenv(DYLD_FALLBACK_LIBRARY_PATH:"C:/Program Files/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre/lib/")
Sys.setenv(JAVA_PATH:"C:/Program Files/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre/lib/")
Sys.setenv(PATH:"C:/Program Files/Java/JavaVirtualMachines/jdk1.8.0_92.jdk/Contents/Home/jre/lib/")
.jcall("java/lang/System", "S", "getProperty", "java.runtime.version")
.jinit()
library(rJava)
library(rJava)
setwd("C:/Users/Dumbo Yeti/Desktop/NWP/Next_Word_Prediction")
shiny::runApp()
